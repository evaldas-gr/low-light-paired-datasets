{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Failas skirtas susipažinti su darbe sudaryto neuroninio tinklo struktūra bei atlikti apmokytų tinklo modelių silpno apšvietimo vaizdų korekciją.\n",
        "\n",
        "Žemiau pateiktame kode:\n",
        "*   Duomenų rinkinių LOL, LoLEG ir LoLEG_triukšmas (LoLEG_noise) paruošimas.\n",
        "*   Pateiktas sudarytas neuroninis tinklas ir jo paruošimas mokymui.\n",
        "*   Sudaryto neuroninio tinklo apmokytų modelių užkrovimas į sistemą.\n",
        "*   Užkrauto modelio silpno apšvietimo vaizdo korekcijos vykdymas.\n",
        "*   Užkrauto modelio duomenų rinkinių metrikų rezultatų lyginimas.\n",
        "\n",
        "\n",
        "Apmokyto tinklo modelių sąrašas:\n",
        "\n",
        "\n",
        "1.   Sudaryto tinklo be praretinimo:\n",
        "  *   Apmokytas su LOL duomenų rinkiniu: ***EGmodel_LOL_combined_losses.h5***\n",
        "  *   Apmokytas su LoLEG duomenų rinkiniu: ***EGmodel_LoLEG_combined_losses.h5***\n",
        "  *   Apmokytas su LoLEG_triukšmas (LoLEG_noise) duomenų rinkiniu: ***EGmodel_LoLEG_noise_combined_losses.h5***\n",
        "2.   Sudaryto tinklo su praretinimu:\n",
        "  *   Apmokytas su LOL duomenų rinkiniu: ***EGmodel_LOL_combined_losses_dilation_2.h5***\n",
        "  *   Apmokytas su LoLEG duomenų rinkiniu: ***EGmodel_LoLEG_combined_losses_dilation_2.h5***\n",
        "  *   Apmokytas su LoLEG_triukšmas (LoLEG_noise) duomenų rinkiniu: ***EGmodel_LoLEG_noise_combined_losses_dilation_2.h5***\n"
      ],
      "metadata": {
        "id": "cKs8Fx5qaEMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kodo vykdymui reikalingų bibliotekų įkėlimas."
      ],
      "metadata": {
        "id": "-vlPk2zAeAUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install pyiqa\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pyiqa\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.io import read_file\n",
        "from tensorflow.image import decode_png\n",
        "from tensorflow.data import Dataset\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from glob import glob\n",
        "from PIL import Image, ImageFont, ImageOps\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, Input, UpSampling2D, Concatenate, LeakyReLU, Multiply, Add, BatchNormalization, GlobalAveragePooling2D, Dense, Reshape\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.utils.layer_utils import count_params"
      ],
      "metadata": {
        "id": "5zT3-D6fdZqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tinklo bei duomenų rinkinių konfigūracija."
      ],
      "metadata": {
        "id": "rqvx0y7keIoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_IMAGE_WIDTH = 600\n",
        "DATASET_IMAGE_HEIGHT = 400\n",
        "IMAGE_SIZE_PER_AXIS = 128\n",
        "IMAGE_SIZE = (IMAGE_SIZE_PER_AXIS, IMAGE_SIZE_PER_AXIS)\n",
        "IMAGE_CHANNEL_NUMBER = 3\n",
        "RGB_MAX = 255\n",
        "BATCH_SIZE = 8\n",
        "NUMBER_OF_EPOCHS = 50\n",
        "INPUT = Input((None, None, IMAGE_CHANNEL_NUMBER))\n",
        "USE_DILATION = False\n",
        "DILATION_RATE = 2\n",
        "CHARBONNIER_LOSS_RATIO = 0.6\n",
        "PERCEPTUAL_LOSS_RATIO = 0.6\n",
        "SSIM_LOSS_RATIO = 0.6\n",
        "\n",
        "PATH_TO_DATASETS = \"/content/\"\n",
        "PATH_TO_MODELS = \"/content/\"\n",
        "LOLEG_NOISE_DATASET_NAME = \"LoLEG_noise\"\n",
        "LOLEG_DATASET_NAME = \"LoLEG\"\n",
        "LOL_DATASET_NAME = \"LOL\"\n",
        "PRIMARY_DATASET_NAME = LOLEG_NOISE_DATASET_NAME\n",
        "SECONDARY_DATASET_NAME = LOLEG_DATASET_NAME\n",
        "TERTIARY_DATASET_NAME = LOL_DATASET_NAME"
      ],
      "metadata": {
        "id": "4mzmD2uueINN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duomenų rinkinių užkrovimas į sistemą ir paruošimas neuroninio tinklo mokymui."
      ],
      "metadata": {
        "id": "sTZVAMOScJ1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7FuBWJsaBhI"
      },
      "outputs": [],
      "source": [
        "train_primary_dataset_low_light_paths = sorted(glob(PATH_TO_DATASETS + PRIMARY_DATASET_NAME + \"/our485/low/*\"))\n",
        "train_primary_dataset_high_light_paths = sorted(glob(PATH_TO_DATASETS + PRIMARY_DATASET_NAME + \"/our485/high/*\"))\n",
        "validate_primary_dataset_low_light_paths = sorted(glob(PATH_TO_DATASETS + PRIMARY_DATASET_NAME + \"/eval15/low/*\"))\n",
        "validate_primary_dataset_path_high_light_paths = sorted(glob(PATH_TO_DATASETS + PRIMARY_DATASET_NAME + \"/eval15/high/*\"))\n",
        "\n",
        "train_secondary_dataset_low_light_paths = sorted(glob(PATH_TO_DATASETS + SECONDARY_DATASET_NAME + \"/our485/low/*\"))\n",
        "train_secondary_dataset_high_light_paths = sorted(glob(PATH_TO_DATASETS + SECONDARY_DATASET_NAME + \"/our485/high/*\"))\n",
        "validate_secondary_dataset_low_light_paths = sorted(glob(PATH_TO_DATASETS + SECONDARY_DATASET_NAME + \"/eval15/low/*\"))\n",
        "validate_secondary_dataset_high_light_paths = sorted(glob(PATH_TO_DATASETS + SECONDARY_DATASET_NAME + \"/eval15/high/*\"))\n",
        "\n",
        "train_tertiary_dataset_low_light_paths = sorted(glob(PATH_TO_DATASETS + TERTIARY_DATASET_NAME + \"/our485/low/*\"))\n",
        "train_tertiary_dataset_high_light_paths = sorted(glob(PATH_TO_DATASETS + TERTIARY_DATASET_NAME + \"/our485/high/*\"))\n",
        "validate_tertiary_dataset_low_light_paths = sorted(glob(PATH_TO_DATASETS + TERTIARY_DATASET_NAME + \"/eval15/low/*\"))\n",
        "validate_tertiary_dataset_high_light_paths = sorted(glob(PATH_TO_DATASETS + TERTIARY_DATASET_NAME + \"/eval15/high/*\"))\n",
        "\n",
        "def load_image(image_path):\n",
        "  loaded_image = read_file(image_path)\n",
        "  decoded_image = decode_png(loaded_image, channels=IMAGE_CHANNEL_NUMBER)\n",
        "  decoded_image.set_shape([None, None, IMAGE_CHANNEL_NUMBER])\n",
        "  normalized_image = tf.cast(decoded_image, dtype=tf.float32) / RGB_MAX\n",
        "\n",
        "  return normalized_image\n",
        "\n",
        "def get_random_crop_by_axis(available_crop_axis_value):\n",
        "  return tf.random.uniform(shape=(), minval=0, maxval=available_crop_axis_value, dtype=tf.int32)\n",
        "\n",
        "def load_low_high_light_images(low_light_image_source_path, high_light_image_source_path):\n",
        "  low_light_image = load_image(low_light_image_source_path)\n",
        "  high_light_image = load_image(high_light_image_source_path)\n",
        "\n",
        "  available_crop_area = (DATASET_IMAGE_WIDTH - IMAGE_SIZE_PER_AXIS + 1, DATASET_IMAGE_HEIGHT - IMAGE_SIZE_PER_AXIS + 1)\n",
        "  random_width_crop = get_random_crop_by_axis(available_crop_area[0])\n",
        "  random_height_crop = get_random_crop_by_axis(available_crop_area[1])\n",
        "\n",
        "  low_light_image = low_light_image[random_height_crop:random_height_crop + IMAGE_SIZE_PER_AXIS, random_width_crop:random_width_crop + IMAGE_SIZE_PER_AXIS]\n",
        "  high_light_image = high_light_image[random_height_crop:random_height_crop + IMAGE_SIZE_PER_AXIS, random_width_crop:random_width_crop + IMAGE_SIZE_PER_AXIS]\n",
        "\n",
        "  return low_light_image, high_light_image\n",
        "\n",
        "def load_dataset_in_batches(low_light_image_paths, high_light_image_paths):\n",
        "  dataset = Dataset.from_tensor_slices((low_light_image_paths, high_light_image_paths))\n",
        "  dataset = dataset.map(load_low_high_light_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "  return dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "train_primary_dataset = load_dataset_in_batches(train_primary_dataset_low_light_paths, train_primary_dataset_high_light_paths)\n",
        "validate_primary_dataset = load_dataset_in_batches(validate_primary_dataset_low_light_paths, validate_primary_dataset_path_high_light_paths)\n",
        "\n",
        "train_secondary_dataset = load_dataset_in_batches(train_secondary_dataset_low_light_paths, train_secondary_dataset_high_light_paths)\n",
        "validate_secondary_dataset = load_dataset_in_batches(validate_secondary_dataset_low_light_paths, validate_secondary_dataset_high_light_paths)\n",
        "\n",
        "train_tertiary_dataset = load_dataset_in_batches(train_tertiary_dataset_low_light_paths, train_tertiary_dataset_high_light_paths)\n",
        "validate_tertiary_dataset = load_dataset_in_batches(validate_tertiary_dataset_low_light_paths, validate_tertiary_dataset_high_light_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neuroninio tinklo paruošimas."
      ],
      "metadata": {
        "id": "ivFNN9FBhrix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrikos\n",
        "\n",
        "def peak_signal_noise_ratio(ground_truth, predicted):\n",
        "  ground_truth = tf.image.convert_image_dtype(ground_truth, tf.float32)\n",
        "  predicted = tf.image.convert_image_dtype(predicted, tf.float32)\n",
        "\n",
        "  return tf.image.psnr(ground_truth, predicted, max_val=1.0)\n",
        "\n",
        "def structural_similarity_index(ground_truth, predicted):\n",
        "  return tf.reduce_mean(tf.image.ssim(ground_truth, predicted, max_val=1.0))\n",
        "\n",
        "# Nuostoliai\n",
        "\n",
        "vgg19 = VGG19(include_top=False, weights=\"imagenet\", input_shape=INPUT.shape[1:])\n",
        "vgg19 = Model(inputs=vgg19.input, outputs=vgg19.get_layer(\"block3_conv3\").output)\n",
        "vgg19.trainable = False\n",
        "\n",
        "def charbonnier_loss(ground_truth, predicted):\n",
        "  return tf.reduce_mean(tf.sqrt(tf.square(ground_truth - predicted) + tf.square(1e-3)))\n",
        "\n",
        "def perceptual_loss(ground_truth, predicted):\n",
        "  ground_truth = vgg19(ground_truth)\n",
        "  predicted = vgg19(predicted)\n",
        "\n",
        "  return MeanSquaredError()(ground_truth, predicted)\n",
        "\n",
        "def calculate_combined_loss(ground_truth, predicted):\n",
        "  charbonnier_loss_value = CHARBONNIER_LOSS_RATIO * charbonnier_loss(ground_truth, predicted)\n",
        "  perceptual_loss_value = PERCEPTUAL_LOSS_RATIO * perceptual_loss(ground_truth, predicted)\n",
        "  ssim_loss_value = SSIM_LOSS_RATIO * (1 - structural_similarity_index(ground_truth, predicted))\n",
        "\n",
        "  return charbonnier_loss_value + perceptual_loss_value + ssim_loss_value"
      ],
      "metadata": {
        "id": "Ajak01cDzajZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neuroninis tinklas\n",
        "\n",
        "def choose_dilation(input, total_filters):\n",
        "  if USE_DILATION:\n",
        "    convolution1 = Conv2D(filters=total_filters, kernel_size=(3,3), activation=LeakyReLU(alpha=0.3), dilation_rate=DILATION_RATE, padding=\"same\")(input)\n",
        "    return Conv2D(filters=total_filters, kernel_size=(3,3), activation=LeakyReLU(alpha=0.3), dilation_rate=DILATION_RATE, padding=\"same\")(convolution1)\n",
        "  else:\n",
        "    convolution1 = Conv2D(filters=total_filters, kernel_size=(3,3), activation=LeakyReLU(alpha=0.3), padding=\"same\")(input)\n",
        "    return Conv2D(filters=total_filters, kernel_size=(3,3), activation=LeakyReLU(alpha=0.3), padding=\"same\")(convolution1)\n",
        "\n",
        "def block(input, total_filters):\n",
        "  convolution1 = choose_dilation(input, total_filters)\n",
        "  normalized = BatchNormalization()(convolution1)\n",
        "\n",
        "  convolution2 = Conv2D(filters=total_filters, kernel_size=(3,3), activation=LeakyReLU(alpha=0.3), padding=\"same\")(normalized)\n",
        "  convolution3 = Conv2D(filters=1, kernel_size=(1,1), activation=LeakyReLU(alpha=0.3), padding=\"same\")(convolution2)\n",
        "  local_features = Multiply()([normalized, convolution3])\n",
        "  local_features = Add()([normalized, local_features])\n",
        "\n",
        "  global_average_pooling = GlobalAveragePooling2D()(normalized)\n",
        "  dense1 = Dense(units=total_filters // 16, activation=LeakyReLU(alpha=0.3))(global_average_pooling)\n",
        "  dense2 = Dense(units=total_filters, activation=\"sigmoid\")(dense1)\n",
        "  global_features = Reshape((1, 1, total_filters))(dense2)\n",
        "  global_features = Multiply()([normalized, global_features])\n",
        "\n",
        "  return Add()([local_features, global_features])\n",
        "\n",
        "def EG_model(input):\n",
        "  block1 = block(input, 64)\n",
        "  convolution1 = Conv2D(filters=64, kernel_size=(2,2), strides=(2,2), padding=\"same\")(block1)\n",
        "  block2 = block(convolution1, 128)\n",
        "  convolution2 = Conv2D(filters=128, kernel_size=(2,2), strides=(2,2), padding=\"same\")(block2)\n",
        "  block3 = block(convolution2, 256)\n",
        "\n",
        "  up_sampled1 = UpSampling2D()(block3)\n",
        "  fusion1 = Concatenate()([up_sampled1, block2])\n",
        "  block4 = block(fusion1, 128)\n",
        "  up_sampled2 = UpSampling2D()(block4)\n",
        "  fusion2 = Concatenate()([up_sampled2, block1])\n",
        "  block5 = block(fusion2, 64)\n",
        "\n",
        "  aggregated_layers = Conv2D(filters=IMAGE_CHANNEL_NUMBER, kernel_size=(1,1), activation=\"sigmoid\")(block5)\n",
        "\n",
        "  return Model(inputs=[input], outputs=[aggregated_layers])\n",
        "\n",
        "model = EG_model(INPUT)\n",
        "\n",
        "model_trainable_parameters = count_params(model.trainable_weights)\n",
        "model_non_trainable_parameters = count_params(model.non_trainable_weights)\n",
        "\n",
        "print(\"Modelio parametrų skaičius: {:,}\".format(model_trainable_parameters + model_non_trainable_parameters))\n",
        "print(\"Mokymui skirtų parametrų skaičius: {:,}\".format(model_trainable_parameters))\n",
        "print(\"Mokymui neskirtų parametrų skaičius: {:,}\".format(model_non_trainable_parameters))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG6aCvjYhrHM",
        "outputId": "9e7077e7-ea05-426e-d0e1-c1da00f0419a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelio parametrų skaičius: 2,941,680\n",
            "Mokymui skirtų parametrų skaičius: 2,940,400\n",
            "Mokymui neskirtų parametrų skaičius: 1,280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neuroninio tinklo mokymas."
      ],
      "metadata": {
        "id": "dWc-wMNhy9WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=calculate_combined_loss,\n",
        "    metrics=[peak_signal_noise_ratio, structural_similarity_index]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_primary_dataset,\n",
        "    validation_data=validate_primary_dataset,\n",
        "    epochs=NUMBER_OF_EPOCHS\n",
        ")\n",
        "\n",
        "plt.plot(history.history[\"loss\"], label=\"Mokymas\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validavimas\")\n",
        "plt.xlabel(\"Epochos\")\n",
        "plt.ylabel(\"Nuostoliai\")\n",
        "plt.title(\"Mokymo ir validavimo nuostoliai epochų metu\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history[\"peak_signal_noise_ratio\"], label=\"Mokymas\")\n",
        "plt.plot(history.history[\"val_peak_signal_noise_ratio\"], label=\"Validavimas\")\n",
        "plt.xlabel(\"Epochos\")\n",
        "plt.ylabel(\"PSNR\")\n",
        "plt.title(\"Mokymo ir validavimo PSNR įvertis epochų metu\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"structural_similarity_index\"], label=\"Mokymas\")\n",
        "plt.plot(history.history[\"val_structural_similarity_index\"], label=\"Validavimas\")\n",
        "plt.xlabel(\"Epochos\")\n",
        "plt.ylabel(\"SSIM\")\n",
        "plt.title(\"Mokymo ir validavimo SSIM įvertis epochų metu\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ylwK-KpZy8xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelių užkrovimo pasirinkimai:\n",
        "1.   Sudaryto tinklo be praretinimo:\n",
        "  *   (1) Apmokytas su LOL duomenų rinkiniu: ***EGmodel_LOL_combined_losses.h5***\n",
        "  *   (2) Apmokytas su LoLEG duomenų rinkiniu: ***EGmodel_LoLEG_combined_losses.h5***\n",
        "  *   (3) Apmokytas su LoLEG_triukšmas (LoLEG_noise) duomenų rinkiniu: ***EGmodel_LoLEG_noise_combined_losses.h5***\n",
        "2.   Sudaryto tinklo su praretinimu:\n",
        "  *   (4) Apmokytas su LOL duomenų rinkiniu: ***EGmodel_LOL_combined_losses_dilation_2.h5***\n",
        "  *   (5) Apmokytas su LoLEG duomenų rinkiniu: ***EGmodel_LoLEG_combined_losses_dilation_2.h5***\n",
        "  *   (6) Apmokytas su LoLEG_triukšmas (LoLEG_noise) duomenų rinkiniu: ***EGmodel_LoLEG_noise_combined_losses_dilation_2.h5***"
      ],
      "metadata": {
        "id": "msg9m-56zOwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chosen_model_path(index):\n",
        "  model_paths = [\"EGmodel_LOL_combined_losses.h5\", \"EGmodel_LoLEG_combined_losses.h5\", \"EGmodel_LoLEG_noise_combined_losses.h5\",\n",
        "                 \"EGmodel_LOL_combined_losses_dilation_2.h5\", \"EGmodel_LoLEG_combined_losses_dilation_2.h5\", \"EGmodel_LoLEG_noise_combined_losses_dilation_2.h5\"]\n",
        "\n",
        "  return model_paths[index - 1]"
      ],
      "metadata": {
        "id": "swBkruSU0kVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_choise = 6\n",
        "\n",
        "custom_objects = {'calculate_combined_loss': calculate_combined_loss, 'peak_signal_noise_ratio': peak_signal_noise_ratio, 'structural_similarity_index': structural_similarity_index}\n",
        "reconstructed_model = keras.models.load_model(PATH_TO_MODELS + get_chosen_model_path(model_choise), custom_objects=custom_objects)"
      ],
      "metadata": {
        "id": "vgM0WsfjyGmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Korekcijos vykdymas su užkrautu tinklo modeliu ir duomenų rinkiniais."
      ],
      "metadata": {
        "id": "2jne5crM1dcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_image(image):\n",
        "  _ = plt.imshow(image)\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "def process_image(image):\n",
        "  image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  image = image[:,:,:] / RGB_MAX\n",
        "  single_batch_image = np.expand_dims(image, axis=0)\n",
        "\n",
        "  start_time = time.perf_counter()\n",
        "  correction_result = reconstructed_model(single_batch_image)\n",
        "\n",
        "  duration = time.perf_counter() - start_time\n",
        "  correction_times.append(duration)\n",
        "\n",
        "  correction_result = correction_result[0] * RGB_MAX\n",
        "  correction_result = Image.fromarray(np.uint8(correction_result))\n",
        "\n",
        "  return correction_result"
      ],
      "metadata": {
        "id": "-uZY9lBF2KaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRIMARY_DATASET\n",
        "\n",
        "images_to_correct = 5\n",
        "correction_times = []\n",
        "images_data = random.sample(train_primary_dataset_low_light_paths + validate_primary_dataset_low_light_paths, images_to_correct)\n",
        "\n",
        "for low_light_image_path in images_data:\n",
        "  low_light_image = Image.open(low_light_image_path)\n",
        "  high_light_image = Image.open(low_light_image_path.replace(\"low\", \"high\"))\n",
        "  correction_result = process_image(low_light_image)\n",
        "  for single_image in [low_light_image, high_light_image, correction_result]:\n",
        "    print_image(single_image)\n",
        "\n",
        "correction_average = sum(correction_times)/len(correction_times)\n",
        "print(\"Korekcijos vykdymo trukmės vidurkis: {0}\".format(correction_average))"
      ],
      "metadata": {
        "id": "1Kq6Wz1x1dLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SECONDARY_DATASET\n",
        "\n",
        "images_to_correct = 5\n",
        "correction_times = []\n",
        "images_data = random.sample(train_secondary_dataset_low_light_paths + validate_secondary_dataset_low_light_paths, images_to_correct)\n",
        "\n",
        "for low_light_image_path in images_data:\n",
        "  low_light_image = Image.open(low_light_image_path)\n",
        "  high_light_image = Image.open(low_light_image_path.replace(\"low\", \"high\"))\n",
        "  correction_result = process_image(low_light_image)\n",
        "  for single_image in [low_light_image, high_light_image, correction_result]:\n",
        "    print_image(single_image)\n",
        "\n",
        "correction_average = sum(correction_times)/len(correction_times)\n",
        "print(\"Korekcijos vykdymo trukmės vidurkis: {0}\".format(correction_average))"
      ],
      "metadata": {
        "id": "RxkaJ39t4xz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TERTIARY_DATASET\n",
        "\n",
        "images_to_correct = 5\n",
        "correction_times = []\n",
        "images_data = random.sample(train_tertiary_dataset_low_light_paths + validate_tertiary_dataset_low_light_paths, images_to_correct)\n",
        "\n",
        "for low_light_image_path in images_data:\n",
        "  low_light_image = Image.open(low_light_image_path)\n",
        "  high_light_image = Image.open(low_light_image_path.replace(\"low\", \"high\"))\n",
        "  correction_result = process_image(low_light_image)\n",
        "  for single_image in [low_light_image, high_light_image, correction_result]:\n",
        "    print_image(single_image)\n",
        "\n",
        "correction_average = sum(correction_times)/len(correction_times)\n",
        "print(\"Korekcijos vykdymo trukmės vidurkis: {0}\".format(correction_average))"
      ],
      "metadata": {
        "id": "Nf22w1uL45Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Korekcijos vykdymas su įkeltu vaizdu."
      ],
      "metadata": {
        "id": "cqoKY2OF5TTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_image_path = \"/img1.png\"\n",
        "correction_times = []\n",
        "\n",
        "low_light_image = Image.open(uploaded_image_path)\n",
        "correction_result = process_image(low_light_image)\n",
        "for single_image in [low_light_image, correction_result]:\n",
        "  print_image(single_image)\n",
        "\n",
        "correction_average = sum(correction_times)/len(correction_times)\n",
        "print(\"Korekcijos vykdymo trukmė: {0}\".format(correction_average))"
      ],
      "metadata": {
        "id": "eR7WJget5QHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duomenų rinkinių įvertinimas metrikomis PSNR, SSIM, BRISQUE, NIQE."
      ],
      "metadata": {
        "id": "_zC4k5KZIQK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_dataset(image_paths):\n",
        "  niqe_metric = pyiqa.create_metric('niqe')\n",
        "  brisque_metric = pyiqa.create_metric('brisque')\n",
        "  brisque_values = []\n",
        "  niqe_values = []\n",
        "  psnr_values = []\n",
        "  ssim_values = []\n",
        "\n",
        "  for low_light_image_path in random.sample(image_paths, len(image_paths)):\n",
        "      low_light_image = Image.open(low_light_image_path)\n",
        "      high_light_image = Image.open(low_light_image_path.replace(\"low\", \"high\"))\n",
        "\n",
        "      correction_image = process_image(low_light_image)\n",
        "\n",
        "      correction_image_for_metrics = to_tensor(correction_image).unsqueeze(0)\n",
        "      high_light_image_for_metrics = to_tensor(high_light_image).unsqueeze(0)\n",
        "\n",
        "      brisque_values.append(brisque_metric(correction_image_for_metrics).item())\n",
        "      niqe_values.append(niqe_metric(correction_image_for_metrics).item())\n",
        "\n",
        "      single_psnr_value = peak_signal_noise_ratio(high_light_image_for_metrics, correction_image_for_metrics)\n",
        "      ssim_correction_image = correction_image_for_metrics.permute(0, 2, 3, 1)\n",
        "      ssim_correction_image_expected = to_tensor(high_light_image).unsqueeze(0).permute(0, 2, 3, 1)\n",
        "      single_ssim_value = structural_similarity_index(ssim_correction_image, ssim_correction_image_expected)\n",
        "      psnr_values.append(single_psnr_value)\n",
        "      ssim_values.append(single_ssim_value)\n",
        "\n",
        "  correction_average = sum(correction_times)/len(correction_times)\n",
        "  brisque_average = sum(brisque_values)/len(brisque_values)\n",
        "  niqe_average = sum(niqe_values)/len(niqe_values)\n",
        "  psnr_average = sum(psnr_values)/len(psnr_values)\n",
        "  ssim_average = sum(ssim_values)/len(ssim_values)\n",
        "\n",
        "  print('[VIDUTINIS] Korekcijos vykdymo trukmė: {0} | BRISQUE: {1} | NIQE: {2} | PSNR: {3} | SSIM: {4}'.format(correction_average, brisque_average, niqe_average, psnr_average, ssim_average))"
      ],
      "metadata": {
        "id": "BC6zBBh9R7Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_primary_dataset_images_paths = train_primary_dataset_low_light_paths + validate_primary_dataset_low_light_paths\n",
        "combined_scondary_dataset_images_paths = train_secondary_dataset_low_light_paths + validate_secondary_dataset_low_light_paths\n",
        "combined_tertiary_dataset_images_paths = train_tertiary_dataset_low_light_paths + validate_tertiary_dataset_low_light_paths\n",
        "\n",
        "correction_times = []\n",
        "evaluate_dataset(combined_primary_dataset_images_paths)\n",
        "correction_times = []\n",
        "evaluate_dataset(combined_scondary_dataset_images_paths)\n",
        "correction_times = []\n",
        "evaluate_dataset(combined_tertiary_dataset_images_paths)"
      ],
      "metadata": {
        "id": "GDvKdVb8HwWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}